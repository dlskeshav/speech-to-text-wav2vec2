# ğŸ§  Speech Recognition with Wav2Vec2 â€” Evaluation on LibriSpeech

This repository demonstrates a mini speech recognition pipeline using Hugging Faceâ€™s **Wav2Vec2** model and the **LibriSpeech** dataset. It evaluates transcription quality using the **Word Error Rate (WER)** metric.

---

## ğŸ“Œ Objective

To evaluate the transcription quality of the `facebook/wav2vec2-base-960h` model on a subset of the LibriSpeech dataset using robust metrics like WER. This serves as a reproducible mini-pipeline for audio-to-text evaluation.

---

## ğŸ“š Dataset

- **Name:** LibriSpeech ASR Corpus
- **Subset Used:** `train.100` â†’ `"clean"` split
- **Accessed via:** Hugging Face Datasets
- **Mode:** Streaming (for low-memory usage)
- **Sample Size:** 10 samples only (for quick demonstration)

---

## ğŸ§  Model Used

- **Model:** [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h)
- **Architecture:** Wav2Vec2 + CTC Head
- **Pre-trained on:** 960 hours of LibriSpeech
- **Sampling Rate:** 16kHz (mono-channel expected)

---

## ğŸ› ï¸ Dependencies

```bash
pip install torch torchaudio transformers datasets evaluate jiwer

